@misc{ebliSimplicialNeuralNetworks2020,
  title = {Simplicial {{Neural Networks}}},
  author = {Ebli, Stefania and Defferrard, Micha{\"e}l and Spreemann, Gard},
  year = {2020},
  month = dec,
  number = {arXiv:2010.03633},
  eprint = {2010.03633},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  urldate = {2023-08-15},
  abstract = {We present simplicial neural networks (SNNs), a generalization of graph neural networks to data that live on a class of topological spaces called simplicial complexes. These are natural multi-dimensional extensions of graphs that encode not only pairwise relationships but also higher-order interactions between vertices - allowing us to consider richer data, including vector fields and \$n\$-fold collaboration networks. We define an appropriate notion of convolution that we leverage to construct the desired convolutional neural networks. We test the SNNs on the task of imputing missing data on coauthorship complexes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Algebraic Topology,Statistics - Machine Learning},
  file = {/Users/mryodo/Zotero/storage/9EDW8NTF/Ebli et al. - 2020 - Simplicial Neural Networks.pdf;/Users/mryodo/Zotero/storage/7F9PIGGI/2010.html}
}

@misc{limHodgeLaplaciansGraphs2019,
  title = {Hodge {{Laplacians}} on Graphs},
  author = {Lim, Lek-Heng},
  year = {2019},
  month = aug,
  number = {arXiv:1507.05379},
  eprint = {1507.05379},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1507.05379},
  urldate = {2023-08-15},
  abstract = {This is an elementary introduction to the Hodge Laplacian on a graph, a higher-order generalization of the graph Laplacian. We will discuss basic properties including cohomology and Hodge theory. The main feature of our approach is simplicity, requiring only knowledge of linear algebra and graph theory. We have also isolated the algebra from the topology to show that a large part of cohomology and Hodge theory is nothing more than the linear algebra of matrices satisfying \$AB = 0\$. For the remaining topological aspect, we cast our discussions entirely in terms of graphs as opposed to less-familiar topological objects like simplicial complexes.},
  archiveprefix = {arxiv},
  keywords = {{05C50, 58A14, 20G10},Computer Science - Information Theory},
  file = {/Users/mryodo/Zotero/storage/8J2QRJM4/Lim - 2019 - Hodge Laplacians on graphs.pdf;/Users/mryodo/Zotero/storage/KDQX2MS4/1507.html}
}

@misc{yangConvolutionalLearningSimplicial2023,
  title = {Convolutional {{Learning}} on {{Simplicial Complexes}}},
  author = {Yang, Maosheng and Isufi, Elvin},
  year = {2023},
  month = jan,
  number = {arXiv:2301.11163},
  eprint = {2301.11163},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-08-15},
  abstract = {We propose a simplicial complex convolutional neural network (SCCNN) to learn data representations on simplicial complexes. It performs convolutions based on the multi-hop simplicial adjacencies via common faces and cofaces independently and captures the inter-simplicial couplings, generalizing state-of-the-art. Upon studying symmetries of the simplicial domain and the data space, it is shown to be permutation and orientation equivariant, thus, incorporating such inductive biases. Based on the Hodge theory, we perform a spectral analysis to understand how SCCNNs regulate data in different frequencies, showing that the convolutions via faces and cofaces operate in two orthogonal data spaces. Lastly, we study the stability of SCCNNs to domain deformations and examine the effects of various factors. Empirical results show the benefits of higher-order convolutions and inter-simplicial couplings in simplex prediction and trajectory prediction.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/mryodo/Zotero/storage/B2CFKXNQ/Yang and Isufi - 2023 - Convolutional Learning on Simplicial Complexes.pdf;/Users/mryodo/Zotero/storage/MEUKSD9X/2301.html}
}
